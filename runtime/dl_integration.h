#pragma once

#ifdef __cplusplus
extern "C" {
#endif

/**
 * @brief Returns non-zero when the binary was compiled with LibTorch support.
 */
int dl_model_supported(void);

/**
 * @brief Returns non-zero if a model is currently loaded.
 */
int dl_model_is_loaded(void);

/**
 * @brief Load a TorchScript model from the given file path.
 *
 * @param model_path Path to a TorchScript (.pt) file.
 * @param prefer_gpu Non-zero to attempt loading the model on CUDA when available.
 * @return 0 on success, non-zero on failure (see dl_model_last_error()).
 */
int dl_model_load(const char* model_path, int prefer_gpu);

/**
 * @brief Run inference on the loaded model.
 *
 * @param input Pointer to input floats.
 * @param input_len Number of floats in input.
 * @param output Pointer to output buffer (will be overwritten).
 * @param output_len Size of output buffer in floats.
 * @return Number of floats written to output on success; negative on failure.
 */
int dl_model_infer(const float* input, int input_len, float* output, int output_len);

/**
 * @brief Unload the currently loaded model (if any).
 */
void dl_model_unload(void);

/**
 * @brief Retrieve the last error message generated by the deep learning bridge.
 *
 * @return Pointer to a null-terminated string owned by the module.
 */
const char* dl_model_last_error(void);

#ifdef __cplusplus
}
#endif
